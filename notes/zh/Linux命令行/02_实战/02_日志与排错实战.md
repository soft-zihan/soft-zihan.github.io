# 🧾 日志与排错实战 (Logs & Troubleshooting)

在真实环境中，**80% 的排障都离不开“看日志”**。本章从“去哪看 + 怎么看 + 怎么分析”三个维度，给出一套可直接上手的日志排错流程。

---

## 1. 日志全景图：系统 vs 应用

- **系统级日志**
  - 传统：写在 `/var/log/*` 下 (`/var/log/syslog`、`/var/log/messages` 等)。
  - 现代 systemd 系统：大量系统日志通过 **journald** 管理，用 `journalctl` 查看。
- **服务/应用日志**
  - Web 服务器：`/var/log/nginx/access.log`、`/var/log/nginx/error.log`
  - 数据库：`/var/log/mysql/error.log`
  - 自研应用：通常在 `/var/log/your_app/` 或运行目录下的 `logs/` 中。

> 经验法则：**出了问题先问自己两件事**  
> 1. 这个东西是 systemd 管的吗？ → 用 `systemctl` + `journalctl`  
> 2. 这个东西是不是有独立的日志文件？ → 去 `/var/log` 或项目根目录找

---

## 2. journalctl：systemd 日志主战场

前一章已经出现过 `journalctl`，这里以**排查为目的**系统化整理一下常用组合。

### 2.1 按服务查看

- 查看某个服务最近的日志：

```bash
journalctl -u nginx
```

- 持续实时滚动（类似 `tail -f`）：

```bash
journalctl -u nginx -f
```

- 只看今天的：

```bash
journalctl -u nginx --since today
```

- 指定时间范围：

```bash
journalctl -u nginx --since "2025-01-01 10:00" --until "2025-01-01 12:00"
```

### 2.2 按严重级别过滤

日志级别从低到高：`debug` < `info` < `notice` < `warning` < `err` < `crit` < `alert` < `emerg`

- 只看错误及以上级别：

```bash
journalctl -u nginx -p err
```

- 实时监听所有错误：

```bash
journalctl -p err -f
```

### 2.3 和 grep 组合

- 查找包含 “timeout” 关键字的日志：

```bash
journalctl -u nginx --since -1h | grep -i timeout
```

> 💡 小技巧：问题刚发生时，直接 `journalctl -xe`  
> 它会显示最近的报错信息和一些提示，经常能直接给出“权限不足”“文件不存在”等线索。

---

## 3. 查看应用日志的通用套路

以 Nginx 为例，演示如何从“服务异常”一路跟到“日志定位”：

### 3.1 确定日志位置

- 通过配置文件：

```bash
grep -n "access_log\|error_log" /etc/nginx/nginx.conf /etc/nginx/conf.d/*.conf
```

- 常见默认路径：
  - `access_log /var/log/nginx/access.log;`
  - `error_log  /var/log/nginx/error.log;`

### 3.2 快速感知错误是否集中爆发

- 统计最近 1000 行错误日志的错误类型分布：

```bash
tail -n 1000 /var/log/nginx/error.log | \
  awk '{print $3}' | sort | uniq -c | sort -rn | head
```

> 思路：先看“**最近发生了什么类型的错误最多**”，再去针对某一类错误深挖。

### 3.3 针对单个请求排查

- 根据 IP 定位某个客户端的所有访问：

```bash
grep "192.168.1.10" /var/log/nginx/access.log | less
```

- 只看非 2xx 的异常请求：

```bash
awk '$9 !~ /^2/ {print}' /var/log/nginx/access.log | less
```

> 说明：Nginx access.log 默认第 9 列是 HTTP 状态码。

### 3.4 日志被切割/压缩后的查看方式

很多系统使用 logrotate，会生成类似：

- `access.log.1`
- `access.log.2.gz`

查看压缩日志：

```bash
zgrep "ERROR" access.log.2.gz
zless access.log.2.gz
```

---

## 4. logrotate：日志自动切割与保留策略

当日志文件无限增长时，磁盘会被慢慢吃满。`logrotate` 用于**自动轮转日志**。

### 4.1 关键概念

- 配置目录：
  - 全局默认：`/etc/logrotate.conf`
  - 单独应用：`/etc/logrotate.d/<app-name>`
- 常见配置字段：
  - `daily/weekly/monthly`：按天/周/月切割
  - `rotate 7`：保留 7 份旧日志
  - `compress`：对旧日志使用 gzip 压缩
  - `maxsize 100M`：超过指定大小就切割

### 4.2 示例：自研应用日志轮转

假设你的应用日志在 `/var/log/myapp/app.log`，可以创建 `/etc/logrotate.d/myapp`：

```conf
/var/log/myapp/app.log {
    daily
    rotate 7
    compress
    missingok
    notifempty
    create 0640 www-data www-data
    postrotate
        systemctl reload myapp.service >/dev/null 2>&1 || true
    endscript
}
```

- 含义：
  - 每天切一次，最多保留 7 份，旧日志自动压缩。
  - 日志为空时不切 (`notifempty`)。
  - 切割后创建新文件并指定权限和属主。
  - 切完后重载服务，让应用重新打开日志文件。

### 4.3 手动触发与测试

- 测试配置是否有语法问题：

```bash
logrotate -d /etc/logrotate.conf
```

- 立刻执行一次轮转：

```bash
sudo logrotate -f /etc/logrotate.conf
```

---

## 5. 常见故障排查实战

### 场景一：网站 502/504 网关错误

1. **确认服务状态**

```bash
systemctl status nginx
systemctl status your-backend
```

2. **看反向代理错误**

```bash
tail -n 50 /var/log/nginx/error.log
```

3. **查后端服务日志**

```bash
journalctl -u your-backend --since -10m
```

4. **提炼出根因**
   - 连接超时 → 后端处理太慢 or 端口不通
   - 连接被拒绝 → 后端没启动 / 监听端口错了

> 建议：**把你排障过程中的命令和结论记在一个 md 文件里**，后面同类问题可以直接照抄。

---

### 场景二：CPU 飙高/机器卡顿

1. 先用 `top`/`htop` 找出最耗 CPU 的进程。
2. 再用日志验证是否是业务流量暴增还是死循环：

```bash
journalctl -u your-app --since -5m | grep -i "error\|timeout\|exception"
```

3. 如果是 Web 服务，可以按 IP 汇总请求量：

```bash
awk '{print $1}' /var/log/nginx/access.log | sort | uniq -c | sort -rn | head
```

---

### 场景三：磁盘空间突然被写满

1. **确认是哪个分区满了**：

```bash
df -h
```

2. **大概率是日志写爆**：先看 `/var/log`：

```bash
sudo du -h /var/log | sort -rh | head
```

3. 针对超大的日志文件：
   - 先确认可否删除或压缩；
   - 临时清空（不推荐长期使用）：`> huge.log`
   - 再补上 `logrotate` 配置，避免再次爆盘。

> 进阶：更系统的磁盘与文件系统排查，见进阶篇的“磁盘与文件系统”一章。

---

## 6. 建立自己的“排障笔记库”

仅仅“会用命令”还不够，更重要的是形成**可复用的排错套路**。

- 每次排障时记录：
  - 发生时间、现象描述
  - 你执行过的命令（按顺序）
  - 日志中的关键片段
  - 最终根因和修复方案
- 推荐结构：
  - `logs/`：原始日志片段（脱敏后）
  - `cases/`：每个案例一个 Markdown，包含“症状 → 调查 → 根因 → 解决 → 避免复发”

长期积累下来，你会拥有一套**专属的生产环境排障手册**，远比任何教程更贴合你的业务。

